{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle MNIST",
      "provenance": [],
      "authorship_tag": "ABX9TyOeqTcuFyPCtuXxKrZBE1f9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/High-Bee/honeycomb/blob/master/Kaggle_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErZ0VgvIbnfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8049c962-c692-4c25-d67b-444e2fe75e36"
      },
      "source": [
        "# # Kaggle MNIST deeplearning\n",
        "\n",
        "# # 필요한 module import\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # Data Loading\n",
        "k_train_mnist = pd.read_csv(\"/content/train.csv\")\n",
        "k_test_mnist = pd.read_csv(\"/content/test.csv\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT-88PI3m7Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(k_train_mnist)\n",
        "\n",
        "x_data = scaler.fit_transform(k_train_mnist.iloc[:,1:])\n",
        "y_data = pd.get_dummies(k_train_mnist[\"label\"]).values\n",
        "\n",
        "pre_x_data = scaler.fit_transform(k_test_mnist.values)\n",
        "\n",
        "\n",
        "# train / test 구분\n",
        "train_num = int(x_data.shape[0] * 0.8)\n",
        "\n",
        "# train data set\n",
        "train_x_data = x_data[:train_num]\n",
        "train_y_data = y_data[:train_num]\n",
        "\n",
        "# test data set\n",
        "test_x_data = x_data[train_num:]\n",
        "test_y_data = y_data[train_num:]\n",
        "\n",
        "# Placeholder\n",
        "tf.reset_default_graph()\n",
        "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
        "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
        "drop_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "# Convolution Layer (Layer1)\n",
        "x_img = tf.reshape(X, [-1,28,28,1]) # 몇장인지 모르고 28,28이고 색은 그레이스케일 1\n",
        "W1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
        "L1 = tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding=\"SAME\") # strides와 padding은 parameter값\n",
        "L1 = tf.nn.relu(L1)\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "# Layer2\n",
        "W2 = tf.Variable(tf.random_normal([3,3,32,64]))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
        "L2 = tf.nn.relu(L2)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "# 이렇게 만든 data를 FC Layer에 넣어서 학습!\n",
        "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
        "#L2.shape # TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])\n",
        "\n",
        "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256],\n",
        "                        initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([256]), name=\"bias3\")\n",
        "_L3 = tf.nn.relu(tf.matmul(L2, W3)+b3)\n",
        "L3 = tf.nn.dropout(_L3, rate=drop_rate)\n",
        "\n",
        "# Layer 4\n",
        "W4 = tf.get_variable(\"weight4\", shape=[256,256],\n",
        "                        initializer=tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([256]), name=\"bias4\")\n",
        "_L4 = tf.nn.relu(tf.matmul(L3, W4)+b4)\n",
        "L4 = tf.nn.dropout(_L4, rate=drop_rate)\n",
        "\n",
        "# Layer 5\n",
        "W5 = tf.get_variable(\"weight5\", shape=[256,10],\n",
        "                        initializer=tf.contrib.layers.xavier_initializer())\n",
        "b5 = tf.Variable(tf.random_normal([10]), name=\"bias5\")\n",
        "\n",
        "# Hypothesis\n",
        "logit = tf.matmul(L4, W5)+b5\n",
        "H = tf.nn.relu(logit)\n",
        "\n",
        "# Cost Function\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
        "                                                                    labels = Y))\n",
        "\n",
        "# train\n",
        "train = tf.train.AdadeltaOptimizer(learning_rate=0.0075).minimize(cost)\n",
        "\n",
        "# Session & reset\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-ut7o-VnK7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "b57a3fbb-9946-45d8-aa54-48133aebb733"
      },
      "source": [
        "%%time\n",
        "# 학습시켜보기! \n",
        "# batch function\n",
        "train_epoch = 250\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "for step in range(train_epoch):\n",
        "    num_of_iter = int(train_x_data.shape[0]/batch_size)\n",
        "    cost_val = 0\n",
        "    for i in range(num_of_iter):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        cut_train_x = train_x_data[start:end]\n",
        "        cut_train_y = train_y_data[start:end]\n",
        "        _, cost_val = sess.run([train, cost], \n",
        "                               feed_dict={ X : cut_train_x,\n",
        "                                            Y : cut_train_y,\n",
        "                                             drop_rate : 0.2})\n",
        "    \n",
        "        \n",
        "    if step % 25 == 0:\n",
        "        print(\"Cost값 : {}\".format(cost_val))\n",
        "      "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost값 : 7.375714302062988\n",
            "Cost값 : 0.5517227649688721\n",
            "Cost값 : 0.3883391320705414\n",
            "Cost값 : 0.3302581012248993\n",
            "Cost값 : 0.32283976674079895\n",
            "Cost값 : 0.19730865955352783\n",
            "Cost값 : 0.09562620520591736\n",
            "Cost값 : 0.1613367795944214\n",
            "Cost값 : 0.16455215215682983\n",
            "Cost값 : 0.10916486382484436\n",
            "CPU times: user 5min 15s, sys: 48.7 s, total: 6min 4s\n",
            "Wall time: 5min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_L80nFwnoub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8acebb50-2f20-4bd7-91b4-d9129447cdb8"
      },
      "source": [
        "# 학습이 종료 되었으니 정확도를 측정\n",
        "\n",
        "predict = tf.argmax(H, 1)\n",
        "correct = tf.equal(predict, tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
        "print(\"정확도는 : {}\".format(sess.run(accuracy, feed_dict={X : test_x_data,\n",
        "                                                          Y : test_y_data,\n",
        "                                                           drop_rate : 0.2})))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도는 : 0.9628571271896362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5sM8g1juDGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # deeplearning test data 예측\n",
        "# from google.colab import files\n",
        "\n",
        "# result = pd.DataFrame(sess.run(tf.argmax(H,1), feed_dict={X:pre_x_data})).reshape([-1,1])\n",
        "\n",
        "# submission = pd.read_csv(\"C:\\Python_DA\\data\\digit-recognizer/sample_submission.csv\")\n",
        "# submission[\"Label\"] = result\n",
        "# submission\n",
        "# submission.to_csv(\"./data/digit-recognizer/dsubmit_4.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AYPyEIMw6W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(k_train_mnist)\n",
        "\n",
        "x_data = scaler.fit_transform(k_train_mnist.iloc[:,1:])\n",
        "y_data = pd.get_dummies(k_train_mnist[\"label\"]).values\n",
        "\n",
        "pre_x_data = scaler.fit_transform(k_test_mnist.values)\n",
        "\n",
        "\n",
        "# train / test 구분\n",
        "train_num = int(x_data.shape[0] * 0.8)\n",
        "\n",
        "# train data set\n",
        "train_x_data = x_data[:train_num]\n",
        "train_y_data = y_data[:train_num]\n",
        "\n",
        "# test data set\n",
        "test_x_data = x_data[train_num:]\n",
        "test_y_data = y_data[train_num:]\n",
        "\n",
        "# placeholder\n",
        "X = tf.placeholder(shape=[None,784], dtype = tf.float32)\n",
        "Y = tf.placeholder(shape=[None,10], dtype = tf.float32)\n",
        "dout_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "# Weight & bias\n",
        "W1 = tf.get_variable(\"weight1\", shape=[784,256], dtype=tf.float32,\n",
        "                    initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
        "_layer1 = tf.nn.relu(tf.matmul(X, W1)+b1)\n",
        "layer1 = tf.nn.dropout(_layer1, rate=dout_rate)\n",
        "\n",
        "# Weight & bias\n",
        "W2 = tf.get_variable(\"weight2\", shape=[256,256], dtype=tf.float32,\n",
        "                    initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
        "_layer2 = tf.nn.relu(tf.matmul(layer1, W2)+b2)\n",
        "layer2 = tf.nn.dropout(_layer2, rate=dout_rate)\n",
        "\n",
        "# Weight & bias\n",
        "W3 = tf.get_variable(\"weight3\", shape=[256,256], dtype=tf.float32,\n",
        "                    initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([256]), name=\"bias3\")\n",
        "_layer3 = tf.nn.relu(tf.matmul(layer2, W3)+b3)\n",
        "layer3 = tf.nn.dropout(_layer3, rate=dout_rate)\n",
        "\n",
        "# Weight & bias\n",
        "W4 = tf.get_variable(\"weight4\", shape=[256,10], dtype=tf.float32,\n",
        "                    initializer=tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([10]), name=\"bias4\")\n",
        "\n",
        "\n",
        "\n",
        "# Hypothesis\n",
        "logit = tf.matmul(layer3, W4) + b4\n",
        "H = tf.nn.relu(logit)\n",
        "\n",
        "# Cost Function\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
        "                                                                    labels=Y))\n",
        "# train node\n",
        "# train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.25).minimize(cost)\n",
        "\n",
        "# session & 초기화\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgjWWZZw_NE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "04a86600-8cb4-4e98-8728-217394e6c94e"
      },
      "source": [
        "%%time\n",
        "# 학습시켜보기! \n",
        "# batch function\n",
        "train_epoch = 200\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "for step in range(train_epoch):\n",
        "    num_of_iter = int(train_x_data.shape[0]/batch_size)\n",
        "    cost_val = 0\n",
        "    for i in range(num_of_iter):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        cut_train_x = train_x_data[start:end]\n",
        "        cut_train_y = train_y_data[start:end]\n",
        "        _, cost_val = sess.run([train, cost], \n",
        "                               feed_dict={ X : cut_train_x,\n",
        "                                            Y : cut_train_y,\n",
        "                                             dout_rate : 0})\n",
        "        \n",
        "    if step % 20 == 0:\n",
        "        print(\"Cost값 : {}\".format(cost_val))\n",
        "      \n",
        "\n",
        "# 학습이 종료 되었으니 정확도를 측정\n",
        "\n",
        "predict = tf.argmax(H, 1)\n",
        "correct = tf.equal(predict, tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
        "print(\"정확도는 : {}\".format(sess.run(accuracy, feed_dict={X : test_x_data,\n",
        "                                                          Y : test_y_data,\n",
        "                                                           dout_rate : 0})))\n",
        "\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost값 : 0.34618645906448364\n",
            "Cost값 : 0.0014522201381623745\n",
            "Cost값 : 0.0002194125554524362\n",
            "Cost값 : 0.00010906925308518112\n",
            "Cost값 : 7.173846097430214e-05\n",
            "Cost값 : 5.296261588227935e-05\n",
            "Cost값 : 4.142304533161223e-05\n",
            "Cost값 : 3.40457700076513e-05\n",
            "Cost값 : 2.8806603950215504e-05\n",
            "Cost값 : 2.4896920876926742e-05\n",
            "정확도는 : 0.9770237803459167\n",
            "CPU times: user 3min 25s, sys: 22.4 s, total: 3min 48s\n",
            "Wall time: 3min\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}